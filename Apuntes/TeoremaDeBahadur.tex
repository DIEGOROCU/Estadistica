\begin{teorema}[Teorema de Bahadur]
	Un estadístico $T = T(X_1, \ldots, X_n)$ es suficiente y completo $\implies$ es minimal suficiente.
\end{teorema}

\begin{proof}
	Por hipótesis del ejercicio sabemos que el estadístio $T$ es suficiente y completo. Además, supongamos que tenemos otro estadístico $S$ suficiente y definamos un tercero $H = E[T|S]$. 
	\begin{observación}
		Recordemos la propiedad de las esperanzas, \underline{propiedad de la torre de la expectativa} o \uline{propiedad de la iteración de la esperanza} que dice que:
		$$E[E[T|\mathcal{G}]] = E[T]$$
		Donde $\mathcal{G}$ es una $\sigma$-álgebra.\\
		No obstante, dado que mayormente se trabaja con estadísticos, podemos denotar: 
		$$E[E[T|S]] = E[T]$$
		Donde $S$ denota en realidad $\sigma(S)$-álgebra (la menor de todas las generadas por S, en particular).
	\end{observación}
	Definamos ahora, el estadístico $L$ dado por $L = E[H|T] \implies$
	$$\begin{cases}
		H = E[T|S] \implies E[H] = E[E[T|S]] = E[T] \\
		L = E[H|T] \implies E[L] = E[E[H|T]] = E[H]
	\end{cases} \implies E[L] = E[H] = E[T]$$

	Sea la función real $g(T) = T - E[H|T]$, entonces, intentemos calcular su esperanza: 
	$$E[g(T)] = E[T - E[H|T]] = E[T] - E[E[H|T]] = E[T] - E[H] = E[T] - E[T] = 0$$
	Entonces, por la completitud de $T$, ésto implica que: 
	$$g(T) \stackrel{c.s.}{=} 0 \implies T = E[H|T]$$
	Esto nos dice que tras intentar estimar $T$ a través de $H = (T|S$), volvemos a obtener $T$, por lo que contiene toda la información necesaria y no tiene información de más, por lo que es minimal suficiente.
\end{proof}